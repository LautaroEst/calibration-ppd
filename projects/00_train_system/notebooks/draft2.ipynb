{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../configs\")\n",
    "import calibration_ppd as cppd\n",
    "from cbow import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 2,\n",
       " 'global_step': 26994,\n",
       " 'pytorch-lightning_version': '1.8.2',\n",
       " 'state_dict': OrderedDict([('model.linear_input.weight',\n",
       "               tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                       [-1.8390, -0.3851, -2.1792,  ..., -0.8572, -0.5408,  0.2237],\n",
       "                       [ 0.6525, -1.9931, -0.1010,  ..., -1.0828, -0.5268,  0.2619],\n",
       "                       ...,\n",
       "                       [-1.1104,  1.2319,  0.2032,  ..., -0.0067, -0.9013, -0.5015],\n",
       "                       [-0.7555, -1.1736, -0.0305,  ...,  0.2236, -0.8586,  0.4816],\n",
       "                       [-0.6124,  0.2246, -1.2404,  ...,  1.4275,  0.5192, -0.7509]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.linear_output.weight',\n",
       "               tensor([[-0.2921,  1.0205, -0.2673,  1.3115, -0.1149, -0.3786,  1.2316,  1.1225,\n",
       "                         1.4766,  1.6235,  1.0615,  0.8173,  0.6962, -0.3798,  1.0116,  1.5037,\n",
       "                         0.6744,  1.2241,  1.2715,  1.7697,  1.0636,  1.1174,  1.0732,  1.3754,\n",
       "                        -0.1997,  1.8592,  0.8078, -0.3948,  1.4899, -0.2496,  0.7865,  1.4391,\n",
       "                        -0.3357,  1.1410,  1.1738, -0.3608,  1.5158,  1.2740, -0.2357, -0.3594,\n",
       "                         1.0238, -0.3401,  1.0308,  1.3458, -0.3227,  0.7411, -0.3123, -0.2612,\n",
       "                         1.4360, -0.2568, -0.1980,  1.1784, -0.3968,  1.3756,  0.7933,  1.2915,\n",
       "                         1.0894,  1.2496, -0.2011, -0.2330, -0.2121, -0.2640,  0.8370,  0.9757,\n",
       "                         1.0417,  0.6712,  1.0139,  1.3337,  1.0053, -0.3378,  0.4286,  1.8230,\n",
       "                         0.8508,  1.4567,  1.0556, -0.0062,  1.5330,  1.6855,  0.6895, -0.4388,\n",
       "                         0.3759,  1.2952, -0.3499, -0.3697,  0.9939, -0.0303, -0.3879,  1.3208,\n",
       "                         1.5588,  1.4657, -0.3786,  1.4632,  1.2986,  0.6803, -0.2175,  0.8964,\n",
       "                        -0.4134, -0.2326, -0.2971, -0.4225,  1.2829,  1.0230, -0.5022, -0.1169,\n",
       "                         0.3029,  1.2408,  0.7892, -0.2797,  0.6444,  1.0713,  1.6387, -0.1860,\n",
       "                        -0.4008,  1.4986, -0.2767,  1.1940,  1.5488, -0.3808,  1.5774,  1.3242,\n",
       "                         1.4699, -0.1579, -0.2352,  1.1372, -0.2929, -0.1336,  0.3123,  0.5388,\n",
       "                         1.2508,  1.3383,  1.2508,  1.0374, -0.3555,  1.4786, -0.2019, -0.3139,\n",
       "                         1.0344,  1.1769,  1.1107, -0.3792, -0.3303, -0.4532,  0.8656, -0.2146,\n",
       "                        -0.3983,  1.3436, -0.7318, -0.3188,  1.6063, -0.3475, -0.3757,  0.6962,\n",
       "                        -0.3269,  1.2550,  0.9087, -0.4117,  1.6694,  1.1126,  1.4265,  0.1969,\n",
       "                        -0.2553, -0.2511, -0.2384, -0.4731, -0.3671, -0.2159, -0.0906,  1.3146,\n",
       "                         1.0929, -0.3084,  0.6338,  1.0781,  1.2021,  1.5860, -0.3105,  1.0196,\n",
       "                        -0.3275,  1.5245,  1.5853, -0.3969,  0.6256,  0.9801,  0.9040,  0.9523,\n",
       "                         0.6967, -0.1928,  1.5850,  1.4357,  0.7847,  0.9087,  0.8846, -0.1834,\n",
       "                         0.7897,  0.7418,  0.3646,  0.9363,  1.3536,  1.4447,  0.5381,  0.9368,\n",
       "                         1.5785,  1.0534, -0.2862, -0.3041, -0.3997,  0.7774,  1.5467, -0.4431,\n",
       "                         1.2413,  1.4407,  1.0154,  1.1647, -0.2480,  0.3395,  1.1259, -0.3452,\n",
       "                         0.6833,  0.9628, -0.4439, -0.2502,  1.4012, -0.2823,  0.7666,  1.2936,\n",
       "                         1.2165,  1.2345, -0.1797,  0.9912,  1.4002,  0.5459, -0.1670,  1.3897,\n",
       "                         1.3148,  0.8142, -0.3397, -0.2821,  0.7507, -0.2928,  1.6499,  1.2821,\n",
       "                        -0.3255,  0.6895,  0.6358, -0.2629, -0.3327, -0.3484, -0.4720,  1.7743,\n",
       "                         1.6692,  1.7273,  0.8365,  0.8396,  1.3550, -0.1587, -0.2080,  0.7058,\n",
       "                         0.8450,  1.9319, -0.4637,  0.2359, -0.1543,  1.5822, -0.3214, -0.3803,\n",
       "                         1.0072,  0.9232, -0.3133,  0.5860,  1.0516,  1.1210, -0.2595, -0.2535,\n",
       "                         0.6236,  1.3708,  1.2155, -0.1097, -0.3589,  1.2844,  0.6620, -0.1284,\n",
       "                         1.2239,  1.9100, -0.2934,  1.9380, -0.2785, -0.3262, -0.3199,  1.0720,\n",
       "                         1.1516, -0.2191,  1.5444, -0.2127,  0.9359,  1.4052,  0.6991, -0.2946,\n",
       "                         0.7440, -0.2169,  1.4897, -0.3025, -0.2113, -0.3867,  1.3102,  1.2401,\n",
       "                         0.5006,  0.7429,  1.6164, -0.3034,  1.3068,  1.0966,  0.7842,  1.8152,\n",
       "                         1.1420, -0.3909,  1.0160,  0.8032,  0.7036,  1.0419, -0.3547, -0.4583,\n",
       "                        -0.2352, -0.4396, -0.2369, -0.1771,  0.9673, -0.2871, -0.3133,  1.0136,\n",
       "                        -0.1364,  1.1826, -0.2794, -0.2895,  0.7286, -0.3374,  1.2930, -0.3358,\n",
       "                        -0.4832,  1.3629, -0.2906, -0.2609, -0.2568,  0.9493, -0.1932, -0.3156,\n",
       "                        -0.2980, -0.3895,  1.2509,  0.7394,  1.4498,  1.6066,  0.7906, -0.3264,\n",
       "                         2.0633, -0.3699,  0.6983,  0.8326,  1.6625,  1.6505,  0.7141, -0.3071,\n",
       "                        -0.4226,  1.1912, -0.3935, -0.3595,  1.8860, -0.3203,  0.9077,  1.0594,\n",
       "                        -0.2223, -0.3831, -0.4468,  1.1283,  1.5879,  1.1660, -0.3220, -0.3340,\n",
       "                        -0.3489,  1.2246, -0.2814,  0.9394,  0.7869,  1.3571,  0.3110,  1.3610,\n",
       "                         1.6858,  1.9325, -0.3644, -0.2051, -0.1895, -0.1971, -0.2417,  0.3855,\n",
       "                         0.9816,  0.8399,  1.0680, -0.2784,  0.8998,  1.0777,  1.2364, -0.3844]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.linear_output.bias',\n",
       "               tensor([-0.5201], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 26993},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 26994,\n",
       "     'completed': 26994,\n",
       "     'started': 26994,\n",
       "     'processed': 26994},\n",
       "    'current': {'ready': 8800,\n",
       "     'completed': 8800,\n",
       "     'started': 8800,\n",
       "     'processed': 8800},\n",
       "    'is_last_batch': False},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.batch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.optimizer_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 26994,\n",
       "       'completed': 26994},\n",
       "      'current': {'ready': 8800, 'completed': 8800}},\n",
       "     'zero_grad': {'total': {'ready': 26994,\n",
       "       'completed': 26994,\n",
       "       'started': 26994},\n",
       "      'current': {'ready': 8800, 'completed': 8800, 'started': 8800}}},\n",
       "    'optimizer_position': 1},\n",
       "   'epoch_loop.batch_loop.manual_loop.state_dict': {},\n",
       "   'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 66,\n",
       "     'completed': 66},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.val_loop.epoch_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 50050,\n",
       "     'completed': 50050,\n",
       "     'started': 50050,\n",
       "     'processed': 50050},\n",
       "    'current': {'ready': 2275,\n",
       "     'completed': 2275,\n",
       "     'started': 2275,\n",
       "     'processed': 2275},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 3,\n",
       "     'completed': 2,\n",
       "     'started': 3,\n",
       "     'processed': 2},\n",
       "    'current': {'ready': 3, 'completed': 2, 'started': 3, 'processed': 2}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'dataloader_progress': {'total': {'ready': 0, 'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.state_dict': {},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': False}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '00_train_system/results/cbow/run00_0/07_Train model/version_0/checkpoints/epoch=2-step=26994.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '00_train_system/results/cbow/run00_0/07_Train model/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(26994.),\n",
       "     'exp_avg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "             [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')},\n",
       "    1: {'step': tensor(26994.),\n",
       "     'exp_avg': tensor([[ 3.5211e-03,  9.5030e-04,  3.5304e-03,  3.4653e-04, -2.1122e-04,\n",
       "               3.3350e-03,  4.2979e-04,  2.6351e-03,  7.0596e-04,  2.6395e-05,\n",
       "               9.0958e-04,  2.7441e-04, -1.7100e-04,  2.9861e-03,  5.5870e-04,\n",
       "               8.2798e-04,  1.6126e-03,  6.5706e-04,  1.3497e-04, -7.7784e-04,\n",
       "               2.8304e-04, -6.2532e-04,  1.0636e-03,  5.3497e-04,  2.4685e-03,\n",
       "               4.4952e-04,  1.9282e-03,  1.0222e-03,  4.4715e-04,  3.1588e-04,\n",
       "               1.5400e-03,  3.7879e-04,  1.4810e-03, -3.2094e-04,  5.6218e-04,\n",
       "               1.2001e-03, -8.1565e-04,  2.9221e-04, -5.7220e-04,  2.8700e-03,\n",
       "               2.1603e-03, -6.4846e-05,  2.1589e-03, -3.6098e-04,  4.8385e-04,\n",
       "               5.4626e-05,  2.9279e-04,  1.2785e-03, -1.9505e-04,  1.5698e-03,\n",
       "               2.0795e-03,  5.5591e-04,  1.9677e-03,  5.3052e-04,  6.5004e-04,\n",
       "               2.8737e-04, -2.9796e-04,  2.2083e-04,  1.8339e-03,  4.3477e-04,\n",
       "               7.3789e-04,  6.8619e-03,  5.1279e-04, -4.5702e-05,  3.1756e-04,\n",
       "               2.1708e-03,  1.5741e-04, -7.8559e-04,  1.1277e-03,  7.5032e-04,\n",
       "               8.3114e-04,  1.8902e-05,  1.0004e-04,  1.2403e-03,  8.2344e-04,\n",
       "              -7.5074e-04,  5.1376e-04,  1.0697e-03,  2.2790e-03,  2.6266e-03,\n",
       "               1.9541e-04, -4.0925e-05,  2.0008e-03,  3.9580e-03,  7.9724e-04,\n",
       "               6.5826e-04, -6.7499e-06,  1.3748e-03, -2.6255e-04,  8.0648e-04,\n",
       "               1.1187e-03, -2.2048e-04,  2.3871e-04, -7.5775e-04,  1.1946e-03,\n",
       "               7.1451e-04,  1.2448e-03,  3.6506e-03,  2.3414e-03,  2.7539e-03,\n",
       "              -3.9421e-04, -2.6355e-04,  2.9416e-03, -7.6787e-05, -2.0399e-04,\n",
       "               1.7480e-05,  1.3611e-04,  2.9399e-03,  3.6616e-04,  1.1575e-03,\n",
       "               9.4181e-04,  1.8761e-03,  1.3553e-03,  1.1979e-04,  1.6901e-03,\n",
       "               1.0181e-04, -3.8096e-04,  4.0734e-03, -2.5194e-04,  1.4845e-04,\n",
       "               1.0012e-03,  7.6822e-05,  2.7595e-04, -1.6387e-03,  3.4242e-03,\n",
       "               1.1825e-03,  8.0917e-04,  9.9835e-04, -2.2866e-04,  1.5019e-05,\n",
       "              -1.4470e-05,  1.0107e-03,  3.2380e-04,  2.0446e-04,  3.3898e-03,\n",
       "               3.1906e-03,  1.8722e-03,  2.0470e-04, -6.2740e-04,  2.0208e-03,\n",
       "               3.9122e-03,  2.0757e-03,  5.1606e-05,  8.0088e-04, -1.8264e-03,\n",
       "               4.2671e-04, -5.5011e-04,  1.6132e-03, -4.5996e-04,  2.7093e-03,\n",
       "               3.4532e-03,  4.2262e-04,  4.2153e-03, -1.1197e-04,  1.6372e-03,\n",
       "               3.9003e-03,  3.5008e-04,  1.3805e-03,  1.8266e-03,  4.2294e-04,\n",
       "              -8.0862e-05,  1.3259e-03,  1.2932e-03,  1.2199e-03,  2.0214e-03,\n",
       "              -5.3473e-04, -1.8884e-04,  4.0977e-04,  1.0861e-03,  3.2591e-03,\n",
       "               4.1572e-04, -7.5501e-04,  9.7554e-04,  3.6423e-04,  1.7460e-03,\n",
       "               1.6076e-03,  3.0849e-03, -3.4582e-05,  1.5210e-04,  1.7541e-03,\n",
       "              -6.1640e-04, -3.2439e-04,  1.9517e-04,  1.4523e-04,  4.8686e-05,\n",
       "               2.7475e-04,  9.3841e-04, -6.4311e-05, -1.7524e-04, -3.0298e-04,\n",
       "              -1.3302e-04,  1.6587e-03,  3.2373e-04,  2.8749e-03,  4.6196e-04,\n",
       "               1.0620e-03, -3.8027e-04, -6.5869e-04,  5.3668e-04,  4.7502e-04,\n",
       "               1.4834e-04, -5.3961e-05,  3.7358e-03,  5.5947e-03,  1.2758e-03,\n",
       "               1.6245e-03,  2.8010e-04, -8.8019e-04,  5.9183e-04,  3.7344e-04,\n",
       "               5.0123e-06,  8.0335e-04,  8.4106e-04, -4.6978e-04, -2.3543e-05,\n",
       "               5.0643e-03,  2.0966e-03,  1.4635e-03,  3.2496e-03,  1.3625e-03,\n",
       "              -7.2665e-04,  1.6888e-03,  8.6080e-04, -1.6326e-04, -6.6823e-04,\n",
       "               1.3020e-03,  1.8283e-03, -5.2293e-04,  1.4408e-04,  3.7384e-04,\n",
       "               2.4200e-03,  5.2522e-04,  3.7351e-04,  5.2565e-04,  3.0486e-03,\n",
       "               2.9568e-03,  2.0423e-03,  1.9518e-03, -8.0527e-04,  1.0774e-04,\n",
       "              -1.0477e-04,  8.5094e-04, -7.1438e-04, -2.0738e-04,  1.8453e-03,\n",
       "               1.8443e-03, -1.4915e-04,  1.0461e-03,  2.7104e-04,  3.2291e-04,\n",
       "               9.6911e-04,  1.5681e-03,  3.8156e-04,  1.6551e-03,  4.0793e-04,\n",
       "               1.3374e-04,  5.0310e-04,  4.5327e-04,  7.2416e-04,  2.9058e-04,\n",
       "               8.6364e-04,  9.0021e-05,  2.9777e-03,  2.0027e-04,  9.4136e-04,\n",
       "              -4.4282e-04, -3.0175e-04,  2.5534e-04,  6.5585e-04,  4.3258e-04,\n",
       "               2.8778e-03, -1.0182e-03,  3.1768e-03,  1.3518e-03,  5.5886e-04,\n",
       "               1.2296e-03,  2.7735e-03, -6.6882e-04,  2.0392e-03,  2.3181e-03,\n",
       "               4.4060e-04, -1.3704e-03,  2.3306e-03,  9.1201e-04,  2.3441e-03,\n",
       "               4.3857e-03,  2.0153e-03, -1.2349e-03, -4.1815e-04,  1.2703e-03,\n",
       "               9.5212e-04,  3.8234e-04,  1.4845e-03, -1.8595e-04,  9.1580e-04,\n",
       "               4.4759e-03,  1.0073e-03,  1.6177e-03,  1.0886e-04,  2.4176e-03,\n",
       "               3.4840e-03, -5.0199e-04,  1.0443e-03,  2.0125e-04,  1.2469e-03,\n",
       "              -1.6836e-04, -3.8172e-04,  7.5131e-04,  3.9579e-04,  2.1278e-03,\n",
       "               3.5537e-04, -4.5845e-04,  4.1722e-04,  4.6035e-03,  6.1208e-04,\n",
       "               1.3309e-03,  4.7918e-04,  9.1808e-04,  1.5136e-03,  3.5653e-03,\n",
       "               6.2995e-04,  1.5266e-03,  1.8568e-03,  1.8954e-03, -7.8410e-04,\n",
       "               1.1332e-03,  6.4005e-04, -1.1194e-03,  2.8522e-03, -3.2288e-04,\n",
       "               4.6697e-03,  1.6163e-03,  1.0586e-03,  1.1789e-04,  7.6555e-04,\n",
       "               3.4022e-03,  1.1554e-03, -4.3860e-05,  2.0899e-03,  3.7714e-03,\n",
       "               3.4599e-04,  7.9723e-04,  2.1214e-03,  3.4426e-03,  1.3879e-03,\n",
       "               2.6208e-03,  8.8468e-04, -4.5738e-04,  2.6174e-04, -5.6682e-04,\n",
       "               1.6500e-03,  2.0641e-03,  6.7267e-05,  7.1212e-03,  2.2892e-04,\n",
       "              -9.3727e-04,  1.1429e-04,  7.9751e-04,  3.0972e-04,  6.0471e-04,\n",
       "               1.1747e-04,  1.3957e-03,  4.1248e-03,  1.6471e-03,  3.9237e-04,\n",
       "               1.1285e-04,  6.5927e-04,  2.2883e-04,  9.1226e-04,  3.4139e-03,\n",
       "               2.0809e-03,  1.0771e-03,  3.8131e-04,  1.0074e-03,  3.4535e-03,\n",
       "               1.2744e-03,  1.0853e-03, -1.6544e-04, -1.0163e-03,  1.1369e-03,\n",
       "               9.2665e-04, -6.8776e-04,  2.5201e-04,  3.3684e-04,  6.0177e-04,\n",
       "               7.2865e-04,  3.6260e-03,  9.4590e-04,  2.7720e-03,  2.4999e-03,\n",
       "               4.7726e-04,  5.1220e-04,  9.6076e-04, -1.3178e-03,  1.1403e-04,\n",
       "               2.9627e-03, -7.3155e-04,  5.5628e-04, -3.0282e-04,  1.9943e-03]],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.5381e-04, 1.2268e-05, 2.2369e-04, 5.8537e-06, 4.9113e-05, 2.7393e-04,\n",
       "              7.7092e-06, 1.5441e-05, 3.7319e-06, 7.7716e-06, 1.7618e-05, 1.6738e-05,\n",
       "              1.2397e-05, 1.7640e-04, 6.4788e-06, 1.0109e-05, 1.5748e-05, 7.8586e-06,\n",
       "              1.0494e-05, 5.5971e-06, 1.9862e-06, 2.4963e-05, 7.7033e-06, 8.8517e-06,\n",
       "              1.0771e-04, 4.7945e-06, 1.5861e-05, 2.1440e-05, 8.0162e-06, 4.4741e-05,\n",
       "              1.9188e-05, 7.4367e-06, 9.4675e-05, 9.0672e-06, 9.8735e-06, 1.2062e-05,\n",
       "              9.9964e-06, 7.0573e-06, 3.1657e-05, 4.8088e-05, 1.1561e-05, 4.7954e-05,\n",
       "              1.0646e-05, 8.0120e-06, 1.7488e-05, 3.1112e-06, 6.6668e-05, 7.0425e-05,\n",
       "              8.9905e-06, 4.9956e-05, 7.7863e-05, 1.1031e-05, 9.4696e-05, 5.4042e-06,\n",
       "              3.3321e-06, 1.0799e-05, 1.7105e-05, 9.0863e-06, 1.0705e-04, 6.9097e-05,\n",
       "              1.6207e-04, 1.3950e-04, 1.1763e-05, 1.4125e-05, 5.4548e-06, 1.4610e-05,\n",
       "              1.2158e-05, 9.3967e-06, 1.8465e-05, 2.3540e-04, 2.3158e-05, 7.9375e-06,\n",
       "              1.2393e-05, 8.7223e-06, 1.3696e-05, 2.9339e-05, 8.3080e-06, 4.7857e-06,\n",
       "              1.8219e-05, 1.2399e-04, 7.3987e-06, 9.4951e-06, 8.0984e-05, 1.2968e-04,\n",
       "              1.0240e-05, 5.5845e-05, 1.7589e-04, 1.1056e-05, 6.9351e-06, 8.3622e-06,\n",
       "              1.6531e-04, 7.4960e-06, 1.0001e-05, 1.6139e-05, 4.4573e-05, 1.6776e-05,\n",
       "              9.6148e-05, 7.6671e-05, 1.7124e-04, 2.5250e-05, 8.2031e-06, 9.7273e-06,\n",
       "              2.2975e-04, 9.8405e-05, 2.0687e-05, 1.0081e-05, 1.1306e-05, 1.5004e-04,\n",
       "              1.7305e-05, 1.1442e-05, 7.0423e-06, 1.6948e-04, 4.1643e-05, 6.5785e-06,\n",
       "              1.7495e-04, 8.1703e-06, 9.3275e-06, 1.5291e-04, 8.9134e-06, 6.5280e-06,\n",
       "              7.7490e-06, 4.6321e-05, 4.5166e-05, 1.1892e-05, 1.7855e-04, 6.8256e-05,\n",
       "              1.5459e-05, 1.9447e-05, 1.2929e-05, 6.0822e-06, 1.0401e-05, 1.5232e-05,\n",
       "              1.0386e-04, 1.1366e-05, 2.0126e-04, 1.1176e-04, 1.0163e-05, 1.2243e-05,\n",
       "              1.0593e-05, 7.0625e-05, 1.0718e-04, 1.6050e-04, 1.6197e-05, 3.7383e-05,\n",
       "              8.4943e-05, 1.1607e-05, 8.3635e-06, 1.9645e-04, 8.8030e-06, 8.0839e-05,\n",
       "              1.7595e-04, 2.0692e-05, 1.4304e-04, 1.3277e-05, 1.8217e-05, 1.8242e-04,\n",
       "              6.2762e-06, 1.1088e-05, 1.0487e-05, 2.3491e-05, 2.2807e-05, 6.1424e-05,\n",
       "              1.0490e-04, 4.0406e-05, 1.1551e-04, 9.2732e-05, 3.8894e-05, 1.0298e-05,\n",
       "              1.1869e-05, 5.6120e-05, 1.8593e-05, 1.3223e-05, 9.4358e-06, 8.9294e-06,\n",
       "              7.2420e-05, 1.3326e-05, 1.1902e-04, 5.5005e-06, 7.7931e-06, 7.3749e-05,\n",
       "              2.4959e-05, 2.1752e-05, 1.5021e-05, 5.1334e-06, 1.1257e-05, 8.7913e-05,\n",
       "              8.6092e-06, 1.2295e-05, 1.0626e-05, 1.1557e-05, 8.5226e-06, 1.0283e-04,\n",
       "              1.4449e-05, 2.1255e-05, 1.7995e-05, 1.2634e-05, 9.9249e-06, 8.5286e-06,\n",
       "              1.4859e-05, 1.4202e-05, 6.9267e-06, 1.3118e-05, 1.5065e-04, 1.4270e-04,\n",
       "              2.3700e-05, 1.4379e-05, 7.8675e-06, 6.2663e-05, 4.2842e-06, 9.5204e-06,\n",
       "              1.3558e-05, 1.3984e-05, 1.3580e-04, 1.7309e-05, 9.0732e-06, 1.7709e-04,\n",
       "              1.7644e-05, 9.7201e-06, 1.0413e-04, 3.8691e-05, 1.0266e-05, 2.1422e-04,\n",
       "              1.1520e-05, 1.7069e-05, 1.0843e-05, 1.0050e-05, 1.3224e-04, 1.1011e-05,\n",
       "              6.3378e-06, 2.0458e-05, 7.5052e-05, 9.0112e-06, 1.2266e-05, 9.4461e-06,\n",
       "              1.4397e-04, 1.2303e-04, 1.5846e-05, 6.0023e-05, 7.2082e-06, 1.6014e-05,\n",
       "              3.4568e-05, 1.5460e-05, 2.3127e-05, 1.3816e-04, 3.4791e-05, 1.2018e-04,\n",
       "              1.8666e-05, 6.3383e-06, 5.5017e-06, 4.2635e-06, 9.0666e-06, 1.3882e-05,\n",
       "              8.6039e-06, 5.2564e-05, 5.6033e-05, 1.5453e-05, 2.0935e-05, 5.3339e-06,\n",
       "              2.2139e-05, 2.9384e-05, 5.1051e-05, 5.8733e-06, 1.4585e-04, 1.2319e-04,\n",
       "              5.2288e-06, 1.2398e-05, 5.4080e-05, 1.4789e-05, 1.2386e-05, 1.2194e-05,\n",
       "              9.5883e-05, 9.5973e-05, 2.7278e-05, 1.2234e-05, 1.0035e-05, 7.9340e-05,\n",
       "              1.4254e-04, 8.5272e-06, 1.5709e-05, 5.7038e-05, 1.3059e-05, 6.8634e-06,\n",
       "              1.0911e-04, 6.8827e-06, 9.7399e-05, 1.0337e-04, 1.5884e-04, 8.7782e-06,\n",
       "              1.1458e-05, 1.8413e-04, 5.3489e-06, 9.2112e-05, 1.6110e-05, 6.5359e-06,\n",
       "              1.8001e-05, 1.7963e-04, 1.9779e-05, 8.3922e-05, 1.0274e-05, 2.9865e-04,\n",
       "              1.1530e-04, 4.3338e-06, 1.0689e-05, 1.2097e-05, 2.7268e-05, 1.3827e-05,\n",
       "              4.4562e-06, 4.2844e-05, 1.2318e-05, 1.8616e-05, 1.0169e-05, 4.8739e-06,\n",
       "              1.0976e-05, 1.5813e-04, 1.5515e-05, 2.5734e-05, 1.1999e-05, 1.7476e-05,\n",
       "              1.6306e-04, 1.7698e-04, 9.6771e-06, 1.2325e-04, 8.0221e-05, 5.2116e-05,\n",
       "              7.5224e-06, 2.1348e-05, 3.9409e-05, 1.2662e-05, 4.8935e-05, 1.6960e-05,\n",
       "              7.3269e-05, 7.7940e-05, 1.2813e-05, 1.5959e-04, 1.5235e-05, 1.4470e-04,\n",
       "              1.9236e-05, 1.3122e-05, 5.8094e-05, 1.3795e-04, 1.2536e-05, 1.3678e-05,\n",
       "              7.4839e-05, 1.3920e-04, 5.5961e-05, 1.7299e-04, 1.2233e-05, 1.0395e-05,\n",
       "              8.7413e-06, 4.8654e-06, 2.5109e-05, 2.2027e-04, 4.7772e-06, 3.5792e-04,\n",
       "              1.9445e-05, 1.5070e-05, 5.6092e-06, 5.5018e-06, 2.1016e-05, 6.8410e-05,\n",
       "              1.4723e-04, 1.6251e-05, 8.9354e-05, 5.8720e-05, 4.8169e-06, 1.8620e-04,\n",
       "              1.3063e-05, 1.4335e-05, 5.4570e-05, 1.3989e-04, 1.2066e-04, 1.2886e-05,\n",
       "              9.5744e-06, 8.3686e-06, 1.0554e-04, 1.8701e-04, 1.1720e-04, 1.2410e-05,\n",
       "              2.0764e-04, 1.6319e-05, 1.2862e-05, 1.1157e-05, 5.4819e-06, 7.3401e-06,\n",
       "              1.1449e-05, 9.6426e-06, 1.5240e-04, 2.6486e-05, 3.2459e-05, 4.6260e-05,\n",
       "              2.6229e-05, 1.3334e-05, 1.5701e-05, 1.8684e-05, 9.0584e-06, 7.0707e-05,\n",
       "              1.8864e-05, 9.2702e-06, 7.2648e-06, 2.3476e-04]], device='cuda:0')},\n",
       "    2: {'step': tensor(26994.),\n",
       "     'exp_avg': tensor([0.0121], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([0.0039], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.001,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0.0,\n",
       "     'amsgrad': False,\n",
       "     'foreach': None,\n",
       "     'maximize': False,\n",
       "     'capturable': False,\n",
       "     'params': [0, 1, 2]}]}],\n",
       " 'lr_schedulers': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(model_name):\n",
    "    results_dir = f\"../results/{model_name}/run00_0/07_Train model/version_0/checkpoints\"\n",
    "    state_dict = torch.load(os.path.join(results_dir,os.listdir(results_dir)[0]))[\"state_dict\"]\n",
    "    if model_name == \"cbow\":\n",
    "        task = cppd.InitTorchModel()\n",
    "\n",
    "model_name = \"cbow\"\n",
    "load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f90631fd6269ecec6b41fd2152e8b981085596aa19ac7b6fcd4ee9a0c7858ce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
