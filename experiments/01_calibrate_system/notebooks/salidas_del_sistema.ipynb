{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_input.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [-0.7959, -0.0367,  1.1788,  ...,  2.0635, -0.6571, -1.9099],\n",
       "                      [-0.5170, -0.0820,  1.3446,  ...,  0.9387, -0.2385, -1.5570],\n",
       "                      ...,\n",
       "                      [ 2.3684, -0.8486, -0.7293,  ...,  0.3443, -0.9120, -0.6359],\n",
       "                      [ 1.0943, -0.0574,  1.2703,  ...,  0.3828,  0.2728,  0.2353],\n",
       "                      [-0.5724, -0.6993, -0.8913,  ..., -2.4182, -0.1794, -1.2246]])),\n",
       "             ('linear_output.weight',\n",
       "              tensor([[ 0.0929, -0.1341, -0.1191,  0.5015,  0.3929,  0.5220, -0.1576,  0.5703,\n",
       "                       -0.2603,  0.2574, -0.2905,  0.5129, -0.3874, -0.0387,  0.4706,  0.6781,\n",
       "                        0.6114,  0.5955,  0.6204,  0.2157,  0.3128,  0.4043,  0.8563, -0.1492,\n",
       "                       -0.1807, -0.2327, -0.2252,  0.1434,  0.4534,  0.5874,  0.4936, -0.2161,\n",
       "                        0.5337, -0.2223,  0.8072,  0.5532, -0.1359,  0.5015, -0.3086,  0.5415,\n",
       "                        0.6313, -0.1418, -0.1089,  0.6112, -0.2416, -0.1804, -0.2904,  0.6209,\n",
       "                       -0.0823,  0.8610,  0.7104,  0.7909, -0.1215,  0.4746,  0.6281,  0.5754,\n",
       "                       -0.1118, -0.0349, -0.2444,  0.5534, -0.1895,  0.8128,  0.3930, -0.1249,\n",
       "                       -0.1375, -0.2778,  0.7250,  0.2981,  0.8349,  0.1288,  0.4867,  0.6863,\n",
       "                        0.7446,  0.5567,  0.6034, -0.2757,  0.5283, -0.1983, -0.1101,  0.4954,\n",
       "                       -0.1400, -0.3076, -0.2192,  0.4261,  0.8499, -0.3469, -0.2850,  0.5612,\n",
       "                        0.3853,  0.5389,  0.5133,  0.3854,  0.3118, -0.1496,  0.2760,  0.5625,\n",
       "                        0.7220,  0.5001,  0.5069,  0.0372, -0.0832,  0.2903,  0.6954,  0.4543,\n",
       "                        0.4831, -0.1237, -0.0966, -0.2909, -0.3225,  0.7385,  0.7252,  0.7451,\n",
       "                        0.8356, -0.1236, -0.2201, -0.0491, -0.0473,  0.0892,  0.5553,  0.6625,\n",
       "                        0.5070,  0.5222, -0.1306,  0.3998, -0.1484, -0.0765,  0.7332,  0.5996,\n",
       "                       -0.1654,  0.3276, -0.3222, -0.3117, -0.0863,  0.5426, -0.1181,  0.3880,\n",
       "                       -0.3164,  0.5318, -0.2142,  0.3694, -0.2493,  0.5269, -0.0239,  0.5638,\n",
       "                       -0.2171, -0.2848,  0.4908, -0.2337,  0.4811, -0.3232, -0.1780,  0.1176,\n",
       "                       -0.1692, -0.0653,  0.3932,  0.6857, -0.2688, -0.1698, -0.1210, -0.2193,\n",
       "                        0.1263,  0.7418, -0.0656, -0.2197,  0.4463, -0.2420,  0.4315, -0.2557,\n",
       "                        0.3305, -0.2317, -0.0795,  0.3232,  0.2869,  0.0877,  0.5318,  0.3331,\n",
       "                       -0.2479, -0.1464,  0.4327,  0.4189,  0.6747,  0.6924,  0.5245, -0.1498,\n",
       "                        0.5936,  0.4728, -0.3543,  0.4903,  0.3263,  0.0487,  0.4978, -0.4041,\n",
       "                        0.4317,  0.2646, -0.2382,  0.1612,  0.7332,  0.4233,  0.4043,  0.6318,\n",
       "                       -0.2419, -0.1782, -0.3120,  0.5307, -0.1099,  0.4181, -0.2955,  0.0513,\n",
       "                        0.4479,  0.3487,  0.6218, -0.3978, -0.0805,  0.8357,  0.7682, -0.2010,\n",
       "                       -0.2015, -0.0432, -0.2745,  0.0276, -0.1237, -0.0178,  0.5738,  0.6937,\n",
       "                        0.2859, -0.1638,  0.6798, -0.1910,  0.4704,  0.4360,  0.4026,  0.6321,\n",
       "                       -0.1474,  0.7339,  0.3816, -0.4004,  0.6200, -0.1644,  0.5065, -0.1085,\n",
       "                        0.8170, -0.2257,  0.4576,  0.3811,  0.3811,  0.2512, -0.0117, -0.1023,\n",
       "                        0.4788,  0.4338,  0.4606,  0.3069, -0.1309,  0.5701, -0.1548,  0.2478,\n",
       "                       -0.2033, -0.3025,  0.7107,  0.4442, -0.0758,  0.5538, -0.3480, -0.0089,\n",
       "                        0.8144, -0.2857,  0.0460,  0.6874,  0.4628,  0.3198,  0.0254,  0.2661,\n",
       "                       -0.0787, -0.2393,  0.6950,  0.3625, -0.1331,  0.5939, -0.2822,  0.3304,\n",
       "                       -0.1991, -0.3340,  0.1158, -0.2222, -0.2651,  0.6008, -0.2720,  0.8886,\n",
       "                        0.6932,  0.4399,  0.5740,  0.7661,  0.6696,  0.5914, -0.1368,  0.5799,\n",
       "                        0.9531,  0.4365, -0.0992,  0.6942, -0.2584, -0.2618,  0.4457,  0.6339,\n",
       "                        0.6873,  0.8357, -0.2259,  0.6015,  0.3870,  0.1469, -0.3082, -0.1123,\n",
       "                       -0.1375,  0.5651, -0.2331,  0.4776, -0.2888, -0.2387,  0.5414,  0.2089,\n",
       "                        0.6465,  0.3874,  0.5833, -0.1252, -0.1575,  0.1021, -0.2363,  0.6354,\n",
       "                        0.2700,  0.7181, -0.2766, -0.1946,  0.7097, -0.2151, -0.1385,  0.9348,\n",
       "                        0.6177, -0.2733,  0.5997, -0.0978,  0.3842,  0.4131,  0.4967,  0.5622,\n",
       "                       -0.0899,  0.5253, -0.2385, -0.0973,  0.3707, -0.0353,  0.6397,  0.4614,\n",
       "                       -0.2994, -0.2830,  0.7887,  0.3436,  0.7097, -0.3229,  0.1875, -0.1800,\n",
       "                        0.7023,  0.0024, -0.1284,  0.4233, -0.1915, -0.0283, -0.1842,  0.6051,\n",
       "                       -0.2908,  0.6147, -0.2371, -0.2383,  0.0816,  0.6018,  0.3663, -0.2252,\n",
       "                       -0.1703,  0.9055, -0.3452, -0.1456,  0.5866,  0.5446, -0.2526,  0.4767,\n",
       "                       -0.3186,  0.4944,  0.4052, -0.1719, -0.0685, -0.0435, -0.3237,  0.4184,\n",
       "                        0.7163,  0.0010,  0.2955,  0.4740,  0.0965, -0.0986,  0.5722,  0.6017]])),\n",
       "             ('linear_output.bias', tensor([-0.3693]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"cbow\"\n",
    "paths = {\n",
    "    \"cbow\": \"../../00_train_system/results/cbow/run00_0/07_Train model/version_0/checkpoints/epoch=0-step=8800.ckpt\",\n",
    "    \"bert\": \"../../00_train_system/results/bert/run00_0/07_Train model/version_0/checkpoints/epoch=0-step=18000.ckpt\"\n",
    "}\n",
    "with open(paths[model_name],\"rb\") as f:\n",
    "    state_dict = OrderedDict([(key.split(\"model.\")[-1], params.cpu()) for key, params in torch.load(paths[model_name])[\"state_dict\"].items()])\n",
    "\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f90631fd6269ecec6b41fd2152e8b981085596aa19ac7b6fcd4ee9a0c7858ce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
